# [üåüCVPR2024üåü]ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More (updating)

This repository contains the official PyTorch implementation of the paper "[ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More](https://vlislab22.github.io/ExACT/)".
<div align="center">
<img src="image/Framework.png" width="1300px">
</div>

---
# Citation
If you find this paper useful, please consider staring üåü this repo and citing üìë our paper:
````
@article{zhou2024exact,
  title={ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More},
  author={Zhou, Jiazhou and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Lin},
  journal={arXiv preprint arXiv:2403.12534},
  year={2024}
}
````
---
# SeAct Dataset

SeAct Dataset: Event action dataset with caption-level labels
We propose the semantic-abundant SeAct dataset for event-text action recognition, where the detailed caption-level label of each action is provided. 
SeAct is collected with a DAVIS346 event camera whose resolution is 346 √ó 260. 
It contains 58 actions under four themes, as presented in the following images. 
Each action is accompanied by an action caption of less than 30 words generated by GPT-4 to enrich the semantic space of the original action labels. 
We split 80% and 20% of each category for training and testing (validating), respectively.

<div align="center">
<img src="image/SeACT.png" width="1300px">
</div>

The following table provides the Download Access to our SeAct dataset, as well as PAF, DVS128Gesture and HARDVS datasets utilized for comparision.

<div align=center>

| Event Datasets |                                             Access to Download                                             | 
|:--------------:|:----------------------------------------------------------------------------------------------------------:|
|     SeAct      |    [Download](https://drive.google.com/drive/folders/1ud_PwnWULqJ-nH8InSuzTxJXUFgTmJkw?usp=drive_link)     |  
|      PAF       |                         [Download](https://github.com/CrystalMiaoshu/PAFBenchmark)                         | 
| DVS128Gesture  | [Download](https://research.ibm.com/publications/a-low-power-fully-event-based-gesture-recognition-system) |
|     HARDVS     |                              [Download](https://github.com/Event-AHU/HARDVS)                               |

</div>

---
# Dependencies
Please refer to [install.md](../ExACT_g/docs/install.md) for step-by-step guidance on how to install the packages.

---
# Ô∏è Ô∏èAcknowledgement
We thank the authors of [CLIP](https://github.com/openai/CLIP), [CoOp](https://github.com/KaiyangZhou/Dassl.pytorch) for opening source their wonderful works.

---
# License
This repository is released under the [MIT](LICENSE) License.

---
# Contact
If you have any question about this project, please feel free to contact jiazhouzhou@hkust-gz.edu.cn.
